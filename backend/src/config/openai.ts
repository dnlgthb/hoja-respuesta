// Cliente de OpenAI - Para an√°lisis de documentos con IA
import OpenAI from 'openai';
import { env } from './env';
import { postProcessQuestion, fixLatexInJsonString } from '../utils/mathPostProcess';

// Crear cliente de OpenAI con timeout generoso para PDFs grandes
const openai = new OpenAI({
  apiKey: env.OPENAI_API_KEY,
  timeout: 180_000, // 3 minutos por llamada
});

// =============================================
// MATHPIX OCR - Specialized math OCR service
// =============================================
const MATHPIX_API_URL = 'https://api.mathpix.com/v3/pdf';

function getMathpixHeaders(): Record<string, string> {
  return {
    'app_id': env.MATHPIX_APP_ID,
    'app_key': env.MATHPIX_APP_KEY,
  };
}

/**
 * Send a full PDF to Mathpix for OCR and return the transcribed text.
 * Mathpix is specialized in math OCR ‚Äî exponentes, fracciones, ra√≠ces.
 * Flow: POST PDF ‚Üí poll status ‚Üí download .mmd (Mathpix Markdown)
 */
async function ocrFullPdfMathpix(pdfBuffer: Buffer): Promise<string> {
  const startTime = Date.now();
  console.log(`  üî¢ Mathpix OCR: sending PDF (${(pdfBuffer.length / 1024 / 1024).toFixed(1)}MB)...`);

  // Step 1: Upload PDF
  const formData = new FormData();
  formData.append('file', new Blob([pdfBuffer], { type: 'application/pdf' }), 'prueba.pdf');
  formData.append('options_json', JSON.stringify({
    math_inline_delimiters: ['$', '$'],
    math_display_delimiters: ['$$', '$$'],
    rm_spaces: true,
  }));

  const uploadResponse = await fetch(MATHPIX_API_URL, {
    method: 'POST',
    headers: getMathpixHeaders(),
    body: formData,
  });

  if (!uploadResponse.ok) {
    const errorText = await uploadResponse.text();
    throw new Error(`Mathpix upload failed (${uploadResponse.status}): ${errorText}`);
  }

  const { pdf_id } = await uploadResponse.json() as { pdf_id: string };
  console.log(`  üî¢ Mathpix: uploaded, pdf_id=${pdf_id}`);

  // Step 2: Poll for completion (max 5 minutes)
  const maxWait = 300_000;
  const pollInterval = 3_000;
  let elapsed = 0;

  while (elapsed < maxWait) {
    await new Promise(resolve => setTimeout(resolve, pollInterval));
    elapsed += pollInterval;

    const statusResponse = await fetch(`${MATHPIX_API_URL}/${pdf_id}`, {
      headers: getMathpixHeaders(),
    });

    if (!statusResponse.ok) {
      const errorText = await statusResponse.text();
      throw new Error(`Mathpix status check failed (${statusResponse.status}): ${errorText}`);
    }

    const status = await statusResponse.json() as {
      status: string;
      percent_done: number;
      num_pages: number;
      num_pages_completed: number;
    };

    if (status.status === 'completed') {
      console.log(`  üî¢ Mathpix: completed ${status.num_pages} pages in ${((Date.now() - startTime) / 1000).toFixed(1)}s`);
      break;
    }

    if (status.status === 'error') {
      throw new Error(`Mathpix processing failed for pdf_id=${pdf_id}`);
    }

    // Log progress every ~15s
    if (elapsed % 15000 < pollInterval) {
      console.log(`  üî¢ Mathpix: ${status.percent_done}% (${status.num_pages_completed}/${status.num_pages} pages)...`);
    }
  }

  if (elapsed >= maxWait) {
    throw new Error(`Mathpix timeout after ${maxWait / 1000}s for pdf_id=${pdf_id}`);
  }

  // Step 3: Download .mmd result
  const mmdResponse = await fetch(`${MATHPIX_API_URL}/${pdf_id}.mmd`, {
    headers: getMathpixHeaders(),
  });

  if (!mmdResponse.ok) {
    const errorText = await mmdResponse.text();
    throw new Error(`Mathpix download failed (${mmdResponse.status}): ${errorText}`);
  }

  const mmdText = await mmdResponse.text();
  const lines = mmdText.split('\n').filter(l => l.trim()).length;
  const totalElapsed = ((Date.now() - startTime) / 1000).toFixed(1);
  console.log(`  üìÑ Mathpix OCR done: ${lines} lines, ${(mmdText.length / 1024).toFixed(1)}KB (${totalElapsed}s)`);

  return mmdText;
}

/**
 * Split Mathpix Markdown text into chunks for Phase 2 structuring.
 * Splits by approximate line count, trying to break at question boundaries.
 */
function splitMathpixTextIntoChunks(text: string, linesPerChunk: number = 120): string[] {
  const lines = text.split('\n');
  if (lines.length <= linesPerChunk) return [text];

  const chunks: string[] = [];
  let currentChunk: string[] = [];

  for (let i = 0; i < lines.length; i++) {
    currentChunk.push(lines[i]);

    if (currentChunk.length >= linesPerChunk) {
      // Try to break at a question boundary (line starting with number + period)
      let breakIdx = currentChunk.length - 1;
      for (let j = currentChunk.length - 1; j >= currentChunk.length - 20 && j >= 0; j--) {
        if (/^\d+\.\s/.test(currentChunk[j])) {
          breakIdx = j;
          break;
        }
      }

      // Push everything before the break point
      chunks.push(currentChunk.slice(0, breakIdx).join('\n'));
      // Start new chunk with the question that was at the break point
      currentChunk = currentChunk.slice(breakIdx);
    }
  }

  if (currentChunk.length > 0) {
    chunks.push(currentChunk.join('\n'));
  }

  return chunks;
}

// =============================================
// PHASE 1: OCR - Faithful visual transcription
// =============================================
const OCR_SYSTEM_PROMPT = `Eres un sistema de OCR especializado en documentos educativos con notaci√≥n matem√°tica.

TU √öNICA TAREA: Transcribir EXACTAMENTE lo que ves en cada p√°gina del PDF. NO interpretes, NO simplifiques, NO reestructures.

REGLAS DE TRANSCRIPCI√ìN:
1. Transcribe CADA p√°gina separ√°ndolas con "--- P√ÅGINA X ---"
2. Copia el texto LITERALMENTE, car√°cter por car√°cter
3. Para expresiones matem√°ticas, usa LaTeX entre $...$
4. Mant√©n la estructura visual: n√∫meros de pregunta, opciones (A, B, C, D), etc.

REGLAS CR√çTICAS PARA NOTACI√ìN MATEM√ÅTICA:

SUPER√çNDICES/EXPONENTES ‚Äî Un n√∫mero o expresi√≥n peque√±o ARRIBA de otro es un EXPONENTE:
  - "14" con "2" peque√±o arriba ‚Üí $14^{2}$
  - "2" con "6" peque√±o arriba ‚Üí $2^{6}$ (NO $26$ ni $2 \\times 6$)
  - "10" con "2" peque√±o arriba ‚Üí $10^{2}$
  - "(888)" con "2" peque√±o arriba ‚Üí $(888)^{2}$
  - NUNCA confundas un exponente con multiplicaci√≥n

PRODUCTOS CON M√öLTIPLES EXPONENTES ‚Äî CADA factor tiene su PROPIO exponente:
  - "2‚Å∂ ¬∑ 111¬≤" ‚Üí $2^{6} \\cdot 111^{2}$ (el 6 es exponente de 2, el 2 es exponente de 111)
  - "3‚Å¥ ¬∑ 7¬≤" ‚Üí $3^{4} \\cdot 7^{2}$ (el 4 es exponente de 3, el 2 es exponente de 7)
  - "2¬≥ ¬∑ 5¬≤ ¬∑ 11" ‚Üí $2^{3} \\cdot 5^{2} \\cdot 11$
  - REGLA: Lee CADA base con SU exponente de izquierda a derecha. NO muevas exponentes entre factores.
  - ERROR COM√öN: "2‚Å∂ ¬∑ 111¬≤" transcrito como "$2 \\cdot 111^{6}$" ‚Äî INCORRECTO, cada exponente pertenece a su base

EXPONENTES FRACCIONARIOS ‚Äî Si el exponente es una fracci√≥n peque√±a arriba:
  - "2" con "9/2" arriba ‚Üí $2^{\\frac{9}{2}}$
  - "2" con "-1/6" arriba ‚Üí $2^{-\\frac{1}{6}}$
  - NUNCA escribas el exponente fraccionario como una fracci√≥n independiente

SUB√çNDICES ‚Äî Un n√∫mero o letra peque√±o ABAJO es un sub√≠ndice:
  - "D" con "AB" abajo ‚Üí $D_{AB}$
  - "x" con "1" abajo ‚Üí $x_{1}$
  - "log" con "2" abajo ‚Üí $\\log_{2}$

RA√çCES:
  - ‚àö2 ‚Üí $\\sqrt{2}$
  - ‚àö(2‚Å∂) ‚Üí $\\sqrt{2^{6}}$
  - ¬≥‚àö8 (ra√≠z c√∫bica) ‚Üí $\\sqrt[3]{8}$
  - ‚Åø‚àöx (ra√≠z n-√©sima) ‚Üí $\\sqrt[n]{x}$
  - NUNCA confundas ‚àö con una fracci√≥n

FRACCIONES ‚Äî Barra horizontal con expresiones arriba y abajo:
  - Numerador arriba, denominador abajo ‚Üí $\\frac{numerador}{denominador}$
  - Fracciones anidadas: $\\frac{\\frac{a}{b}}{\\frac{c}{d}}$

PRODUCTO/MULTIPLICACI√ìN:
  - Punto centrado (¬∑) ‚Üí $\\cdot$
  - Signo √ó ‚Üí $\\times$
  - Multiplicaci√≥n impl√≠cita (2x sin s√≠mbolo) ‚Üí $2x$

LOGARITMOS:
  - log‚ÇÇ(x) ‚Üí $\\log_{2}(x)$
  - ln(x) ‚Üí $\\ln(x)$
  - log(x) ‚Üí $\\log(x)$

TRIGONOMETR√çA:
  - sen(x) o sin(x) ‚Üí $\\sin(x)$
  - cos(x) ‚Üí $\\cos(x)$
  - tan(x) ‚Üí $\\tan(x)$
  - sin¬≤(x) ‚Üí $\\sin^{2}(x)$

CONJUNTOS:
  - ‚à© (intersecci√≥n) ‚Üí $\\cap$
  - ‚à™ (uni√≥n) ‚Üí $\\cup$
  - ‚àà (pertenece) ‚Üí $\\in$
  - ‚äÇ (subconjunto) ‚Üí $\\subset$

OTROS S√çMBOLOS:
  - ¬∞ (grados) ‚Üí $^{\\circ}$ (ej: $135^{\\circ}$)
  - œÄ ‚Üí $\\pi$
  - ‚àû ‚Üí $\\infty$
  - ‚â§ ‚Üí $\\leq$, ‚â• ‚Üí $\\geq$, ‚â† ‚Üí $\\neq$
  - ‚Üí (flecha) ‚Üí $\\to$
  - ¬± ‚Üí $\\pm$
  - Notaci√≥n cient√≠fica: 2√ó10‚Åª‚Åµ ‚Üí $2 \\times 10^{-5}$

VECTORES:
  - Flecha sobre letra ‚Üí $\\vec{u}$, $\\vec{v}$

FORMATO DE SALIDA ‚Äî Texto plano con la transcripci√≥n fiel de cada p√°gina.
Si una p√°gina es portada, instrucciones o est√° en blanco, escribe "[P√°gina de instrucciones/portada/blanco]".
Si hay una imagen, tabla o gr√°fico, descr√≠belo entre corchetes: [Imagen: descripci√≥n]
Si las opciones de una pregunta son im√°genes/gr√°ficos, descr√≠belas: "A) [Gr√°fico: descripci√≥n]"`;

// =============================================
// PHASE 2: Structuring - Parse OCR into JSON
// =============================================
const STRUCTURE_SYSTEM_PROMPT = `Eres un asistente que estructura texto transcrito de pruebas educativas en formato JSON.

Recibir√°s la transcripci√≥n fiel (OCR) de una prueba. Tu trabajo es ESTRUCTURAR ese texto en JSON, sin modificar las expresiones matem√°ticas.

INSTRUCCIONES:
1. Identifica cada pregunta por su n√∫mero
2. Clasifica el tipo seg√∫n las reglas de abajo
3. Extrae el texto completo, opciones y contexto
4. Las expresiones matem√°ticas ya vienen en LaTeX con $...$  ‚Äî c√≥pialas TAL CUAL

CLASIFICACI√ìN DE TIPO:
- MULTIPLE_CHOICE: Tiene opciones A), B), C), D). La gran mayor√≠a de preguntas en pruebas estandarizadas son de este tipo.
- TRUE_FALSE: Afirmaci√≥n para evaluar como Verdadera o Falsa. Puede requerir justificaci√≥n.
- MATH: Pregunta abierta donde el estudiante debe dar un resultado num√©rico/expresi√≥n. Se√±ales: "Calcula", "Determina el valor", "Resuelve". NO tiene opciones.
- DEVELOPMENT: Pregunta abierta de redacci√≥n/explicaci√≥n. Se√±ales: "Explica", "Justifica", "Analiza", "Describe". NO tiene opciones.
NOTA: Si una pregunta tiene opciones A/B/C/D, SIEMPRE es MULTIPLE_CHOICE, sin importar si el contenido es matem√°tico.

REGLAS PARA EXPRESIONES MATEM√ÅTICAS:
- NUNCA modifiques las expresiones de la transcripci√≥n
- Copia EXACTAMENTE: $14^{2}$, $(888)^{2}$, $2^{6} \\cdot 111^{2}$, etc.
- NO cambies \\cdot por \\times ni viceversa ‚Äî copia el operador exacto del texto
- NO cambies \\sqrt{X} por \\sqrt(X) ‚Äî mant√©n las llaves {} tal como est√°n
- NO cambies \\mathrm por \\text ni viceversa ‚Äî copia el comando exacto
- Opciones: incluye la letra y contenido completo. Ej: "A) $2^{6} \\cdot 111^{2}$"
- Si una opci√≥n dice "[Ver imagen en el PDF]" o similar, mantenlo

VALIDACI√ìN DE OPCIONES:
- MULTIPLE_CHOICE debe tener exactamente 4 opciones (A, B, C, D)
- Si solo encuentras 3 opciones visibles y hay una imagen, la 4ta podr√≠a estar en la imagen
- NO inventes opciones que no est√©n en la transcripci√≥n

PREGUNTAS CON IM√ÅGENES:
- Si la transcripci√≥n indica [Imagen: ...], pon has_image: true y la descripci√≥n en image_description
- Si las opciones son im√°genes descritas, incl√∫yelas como texto descriptivo

PREGUNTAS ANIDADAS/COMPUESTAS:
- Si hay un enunciado general para varias sub-preguntas, ponlo en "context" de cada sub-pregunta

Responde √öNICAMENTE con JSON v√°lido:
{
  "questions": [
    {
      "number": "1",
      "type": "MULTIPLE_CHOICE",
      "text": "¬øCu√°l es el resultado de $3 - (-1)(-1-5)$?",
      "context": null,
      "options": ["A) $-1$", "B) $-3$", "C) $-12$", "D) $-24$"],
      "correct_answer": null,
      "points": 1,
      "has_image": false,
      "image_description": null,
      "image_page": null
    }
  ]
}

IMPORTANTE:
- "text" DEBE incluir la instrucci√≥n completa, no solo la f√≥rmula
- "number" es STRING (permite "I.a", "2.b", etc.)
- Si hay puntaje indicado, √∫salo; si no, usa 1 punto
- Si no hay preguntas en la transcripci√≥n, retorna {"questions": []}
- NO omitas preguntas ‚Äî si la transcripci√≥n tiene preguntas 1-15, el JSON debe tener las 15`;

// Tipo para callback de progreso
export type ProgressCallback = (data: {
  type: 'progress';
  batch: number;
  totalBatches: number;
  pages: string;
  questionsFound: number;
  message: string;
}) => void;

/**
 * PHASE 1: OCR - Send PDF chunk to vision model for faithful transcription.
 * Returns raw text transcription, NOT structured JSON.
 */
async function ocrPdfChunk(
  chunkBase64: string,
  chunkInfo: string
): Promise<string> {
  const startTime = Date.now();
  console.log(`  üëÅÔ∏è Phase 1 (OCR): ${chunkInfo} ‚Äî modelo: ${env.OPENAI_VISION_MODEL}`);

  const completion = await openai.chat.completions.create({
    model: env.OPENAI_VISION_MODEL,
    messages: [
      {
        role: 'system',
        content: OCR_SYSTEM_PROMPT,
      },
      {
        role: 'user',
        content: [
          {
            type: 'text',
            text: `Transcribe FIELMENTE todo el contenido de este fragmento de prueba educativa (${chunkInfo}). Copia exactamente lo que ves, especialmente la notaci√≥n matem√°tica con exponentes, ra√≠ces y fracciones. Usa LaTeX entre $...$ para las expresiones matem√°ticas.`,
          },
          {
            type: 'file',
            file: {
              filename: 'prueba.pdf',
              file_data: `data:application/pdf;base64,${chunkBase64}`,
            },
          },
        ],
      },
    ],
    temperature: 0.0,
    max_tokens: 16000,
  });

  const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);
  const transcription = completion.choices[0].message.content || '';
  const lines = transcription.split('\n').filter(l => l.trim()).length;

  console.log(`  üìÑ Phase 1 done: ${lines} lines transcribed (${elapsed}s)`);
  return transcription;
}

/**
 * PHASE 2: Structure - Send OCR transcription to text model to parse into JSON.
 * No vision needed here, just text comprehension.
 */
async function structureTranscription(
  transcription: string,
  chunkInfo: string
): Promise<any[]> {
  const startTime = Date.now();
  console.log(`  üèóÔ∏è Phase 2 (Structure): parsing transcription into JSON ‚Äî modelo: ${env.OPENAI_MODEL}`);

  const completion = await openai.chat.completions.create({
    model: env.OPENAI_MODEL,
    messages: [
      {
        role: 'system',
        content: STRUCTURE_SYSTEM_PROMPT,
      },
      {
        role: 'user',
        content: `Aqu√≠ est√° la transcripci√≥n fiel (OCR) de un fragmento de prueba educativa (${chunkInfo}). Estructura las preguntas en formato JSON. COPIA las expresiones matem√°ticas EXACTAMENTE como est√°n en la transcripci√≥n, sin modificar nada.\n\nTRANSCRIPCI√ìN:\n${transcription}`,
      },
    ],
    temperature: 0.0,
    max_tokens: 16000,
    response_format: { type: 'json_object' },
  });

  const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);
  const responseText = completion.choices[0].message.content || '{}';

  // Fix LaTeX backslashes BEFORE JSON.parse to prevent escape destruction
  const fixedJson = fixLatexInJsonString(responseText);
  if (fixedJson !== responseText) {
    console.log(`  üîß Fixed LaTeX escapes in JSON response`);
  }

  const parsed = JSON.parse(fixedJson);
  const rawQuestions = parsed.questions || [];

  console.log(`  üìù Phase 2 done: ${rawQuestions.length} questions structured (${elapsed}s)`);

  // Post-process: convert Unicode math to LaTeX, fix bare commands, repair broken escapes
  const questions = rawQuestions.map((q: any) => postProcessQuestion(q));

  return questions;
}

/**
 * Two-phase analysis of a PDF chunk:
 * Phase 1 (OCR): Vision model transcribes the PDF faithfully as text
 * Phase 2 (Structure): Text model parses the transcription into JSON
 */
async function analyzeDocumentChunk(
  chunkBase64: string,
  chunkInfo: string
): Promise<any[]> {
  // Phase 1: Faithful OCR transcription
  const transcription = await ocrPdfChunk(chunkBase64, chunkInfo);

  // Skip only completely empty transcriptions
  if (!transcription.trim()) {
    console.log(`  ‚è≠Ô∏è Skipping chunk (empty transcription): ${chunkInfo}`);
    return [];
  }

  // Don't skip chunks that contain instruction/cover page markers ‚Äî
  // they may also contain questions on other pages within the same chunk.
  // Phase 2 (Structure) will simply return [] if no questions are found.

  // Phase 2: Structure into JSON
  const questions = await structureTranscription(transcription, chunkInfo);

  return questions;
}

/**
 * Analizar PDF con vision API y extraer preguntas.
 * Para PDFs grandes (>15 p√°ginas), divide en chunks y procesa cada uno por separado.
 * @param chunks - Array de chunks del PDF (de splitPdfIntoChunks)
 * @param onProgress - Optional callback para reportar progreso
 * @returns Array de preguntas estructuradas
 */
export async function analyzeDocument(
  chunks: Array<{ base64: string; startPage: number; endPage: number; totalPages: number }>,
  onProgress?: ProgressCallback
) {
  // Un solo chunk ‚Üí llamada directa
  if (chunks.length === 1) {
    console.log(`üìÑ Analizando PDF completo (${chunks[0].totalPages} p√°ginas)...`);
    onProgress?.({
      type: 'progress',
      batch: 1,
      totalBatches: 1,
      pages: `1-${chunks[0].totalPages}`,
      questionsFound: 0,
      message: `Analizando PDF (${chunks[0].totalPages} p√°ginas)...`,
    });
    const questions = await analyzeDocumentChunk(chunks[0].base64, `${chunks[0].totalPages} p√°ginas`);
    console.log(`üìÑ Completado: ${questions.length} preguntas encontradas`);
    return questions;
  }

  // M√∫ltiples chunks ‚Üí procesar en paralelo de a CONCURRENCY chunks
  const CONCURRENCY = 2;
  console.log(`üìÑ PDF grande: ${chunks[0].totalPages} p√°ginas ‚Üí ${chunks.length} batches (concurrencia: ${CONCURRENCY})`);
  const allQuestions: any[] = [];

  for (let i = 0; i < chunks.length; i += CONCURRENCY) {
    const batch = chunks.slice(i, i + CONCURRENCY);
    const batchPromises = batch.map((chunk, j) => {
      const idx = i + j;
      const chunkInfo = `p√°ginas ${chunk.startPage}-${chunk.endPage} de ${chunk.totalPages}`;
      console.log(`  üîÑ Batch ${idx + 1}/${chunks.length}: ${chunkInfo}...`);
      return analyzeDocumentChunk(chunk.base64, chunkInfo).then(questions => {
        console.log(`  ‚úÖ Batch ${idx + 1}: ${questions.length} preguntas encontradas`);
        return { idx, questions };
      });
    });

    // Report progress for this parallel group
    const pagesStr = batch.map(c => `${c.startPage}-${c.endPage}`).join(', ');
    onProgress?.({
      type: 'progress',
      batch: Math.min(i + CONCURRENCY, chunks.length),
      totalBatches: chunks.length,
      pages: pagesStr,
      questionsFound: allQuestions.length,
      message: `Procesando batches ${i + 1}-${Math.min(i + CONCURRENCY, chunks.length)} de ${chunks.length} (p√°gs. ${pagesStr})...`,
    });

    const results = await Promise.all(batchPromises);
    // Sort by original index to maintain page order
    results.sort((a, b) => a.idx - b.idx);
    for (const r of results) {
      allQuestions.push(...r.questions);
    }
  }

  console.log(`üìÑ Total: ${allQuestions.length} preguntas extra√≠das de ${chunks.length} batches`);
  return allQuestions;
}

/**
 * Analyze a PDF using Mathpix for OCR (Phase 1) + gpt-4o-mini for structuring (Phase 2).
 * Mathpix is specialized in math OCR ‚Äî produces perfect LaTeX for exponents, fractions, roots.
 * @param pdfBuffer - Full PDF as Buffer
 * @param onProgress - Optional callback for progress updates
 * @returns Array of structured questions
 */
export async function analyzeDocumentMathpix(
  pdfBuffer: Buffer,
  onProgress?: ProgressCallback
) {
  // Phase 1: Mathpix OCR ‚Äî whole PDF at once
  onProgress?.({
    type: 'progress',
    batch: 1,
    totalBatches: 3,
    pages: 'all',
    questionsFound: 0,
    message: 'Enviando PDF a Mathpix OCR...',
  });

  const fullText = await ocrFullPdfMathpix(pdfBuffer);

  // Split text into chunks for Phase 2
  const textChunks = splitMathpixTextIntoChunks(fullText, 120);
  console.log(`üìÑ Mathpix text split into ${textChunks.length} chunks for structuring`);

  // Phase 2: Structure each text chunk with gpt-4o-mini
  const CONCURRENCY = 2;
  const allQuestions: any[] = [];

  for (let i = 0; i < textChunks.length; i += CONCURRENCY) {
    const batch = textChunks.slice(i, i + CONCURRENCY);
    const batchPromises = batch.map((chunk, j) => {
      const idx = i + j;
      const chunkInfo = `texto chunk ${idx + 1} de ${textChunks.length}`;
      console.log(`  üîÑ Structure ${idx + 1}/${textChunks.length}...`);
      return structureTranscription(chunk, chunkInfo).then(questions => {
        console.log(`  ‚úÖ Structure ${idx + 1}: ${questions.length} preguntas`);
        return { idx, questions };
      });
    });

    onProgress?.({
      type: 'progress',
      batch: Math.min(i + CONCURRENCY, textChunks.length) + 1,
      totalBatches: textChunks.length + 1,
      pages: `chunk ${i + 1}-${Math.min(i + CONCURRENCY, textChunks.length)}`,
      questionsFound: allQuestions.length,
      message: `Estructurando preguntas (chunk ${i + 1}-${Math.min(i + CONCURRENCY, textChunks.length)} de ${textChunks.length})...`,
    });

    const results = await Promise.all(batchPromises);
    results.sort((a, b) => a.idx - b.idx);
    for (const r of results) {
      allQuestions.push(...r.questions);
    }
  }

  console.log(`üìÑ Total: ${allQuestions.length} preguntas extra√≠das (Mathpix + ${textChunks.length} structure calls)`);
  return allQuestions;
}

/**
 * Analizar contenido de archivo Excel/CSV y extraer estudiantes
 * @param content - Contenido del archivo como texto
 * @returns Array de estudiantes con nombre y email
 */
export async function extractStudentsFromFile(content: string) {
  const prompt = `Analiza este contenido de archivo Excel/CSV y extrae la lista de estudiantes.
Busca nombres completos de personas y emails (si existen).

REGLAS IMPORTANTES:
1. Extrae TODOS los nombres de personas que encuentres
2. Ignora encabezados como "Nombre", "Estudiante", "Email", "N¬∞", etc.
3. Ignora n√∫meros de lista al inicio de filas (1, 2, 3...)
4. Solo omite un nombre si est√° EXPL√çCITAMENTE tachado (con ~~texto~~ o caracteres de tachado)
5. NO omitas nombres solo porque est√°n cerca de otros tachados
6. Cada nombre debe evaluarse INDIVIDUALMENTE - si no tiene marcas de tachado, INCL√öYELO
7. En caso de duda, INCLUYE el nombre (es mejor incluir de m√°s que omitir)

Responde SOLO con JSON v√°lido en este formato:
{
  "students": [
    { "name": "Nombre Completo", "email": "email@ejemplo.com" },
    { "name": "Otro Nombre", "email": null }
  ]
}

Contenido del archivo:
${content}`;

  const completion = await openai.chat.completions.create({
    model: env.OPENAI_MODEL,
    messages: [
      {
        role: 'system',
        content: 'Eres un experto en procesamiento de datos. Extraes nombres de estudiantes de archivos de lista. Respondes solo en formato JSON v√°lido.',
      },
      {
        role: 'user',
        content: prompt,
      },
    ],
    temperature: 0.1, // Muy baja para resultados consistentes
    response_format: { type: 'json_object' },
  });

  const responseText = completion.choices[0].message.content || '{}';
  const parsed = JSON.parse(responseText);

  return parsed.students || [];
}

/**
 * Corregir respuesta de desarrollo o matem√°tica con IA
 * @param params - Par√°metros de correcci√≥n
 * @returns Puntaje y feedback
 */
export async function correctWithAI(params: {
  questionType: 'DEVELOPMENT' | 'MATH';
  questionText: string;
  correctionCriteria: string;
  maxPoints: number;
  studentAnswer: string;
}): Promise<{ pointsEarned: number; feedback: string }> {
  const { questionType, questionText, correctionCriteria, maxPoints, studentAnswer } = params;

  // Para MATH: solo comparar resultado, NO pedir procedimiento
  const typeDescription = questionType === 'MATH'
    ? 'Esta es una pregunta de MATEM√ÅTICAS. Solo compara el RESULTADO FINAL con la pauta. NO eval√∫es procedimiento.'
    : 'Esta es una pregunta de DESARROLLO. Eval√∫a la comprensi√≥n conceptual, claridad de expresi√≥n y uso correcto de t√©rminos.';

  const mathInstructions = questionType === 'MATH'
    ? `
REGLAS PARA MATEM√ÅTICAS:
- SOLO compara el resultado num√©rico/expresi√≥n del estudiante con la pauta
- Si el resultado coincide (mismo valor): puntaje completo
- Si no coincide: 0 puntos
- NUNCA pidas "desarrollo", "procedimiento" o "demostraci√≥n"
- El feedback solo dice si es correcto o incorrecto`
    : '';

  const prompt = `Eres un profesor evaluando la respuesta de un estudiante.

${typeDescription}

PREGUNTA:
${questionText}

PAUTA DE CORRECCI√ìN (respuesta esperada):
${correctionCriteria || 'No se proporcion√≥ pauta espec√≠fica.'}

PUNTAJE M√ÅXIMO: ${maxPoints} puntos

RESPUESTA DEL ESTUDIANTE:
${studentAnswer}
${mathInstructions}

Responde SOLO con JSON:
{
  "pointsEarned": <n√∫mero entre 0 y ${maxPoints}>,
  "feedback": "<feedback breve>"
}`;

  // DEBUG: Log completo ANTES de llamar a la IA
  console.log('\n========== DEBUG correctWithAI ==========');
  console.log('Modelo:', env.OPENAI_MODEL);
  console.log('Tipo:', questionType);
  console.log('Pregunta:', questionText);
  console.log('Pauta (correctionCriteria):', correctionCriteria);
  console.log('Respuesta estudiante:', studentAnswer);
  console.log('Puntaje m√°ximo:', maxPoints);
  console.log('--- PROMPT COMPLETO ---');
  console.log(prompt);
  console.log('--- FIN PROMPT ---');

  const completion = await openai.chat.completions.create({
    model: env.OPENAI_MODEL,
    messages: [
      {
        role: 'system',
        content: 'Eres un profesor experto en evaluaci√≥n educativa. Corriges respuestas de manera justa. Respondes solo en formato JSON v√°lido.',
      },
      {
        role: 'user',
        content: prompt,
      },
    ],
    temperature: 0.3,
    response_format: { type: 'json_object' },
  });

  const responseText = completion.choices[0]?.message.content || '{}';

  // DEBUG: Log de la respuesta de la IA
  console.log('--- RESPUESTA IA ---');
  console.log(responseText);
  console.log('========== FIN DEBUG correctWithAI ==========\n');

  const parsed = JSON.parse(responseText);

  return {
    pointsEarned: typeof parsed.pointsEarned === 'number' ? parsed.pointsEarned : 0,
    feedback: parsed.feedback || 'No se pudo generar feedback.',
  };
}

/**
 * Corregir pregunta V/F con justificaci√≥n de respuestas falsas
 * @param params - Par√°metros de correcci√≥n
 * @returns Puntaje y feedback
 */
export async function correctTrueFalseWithJustification(params: {
  questionText: string;
  correctAnswer: string;
  studentAnswer: string;
  justification: string | null;
  correctionCriteria: string | null;
  maxPoints: number;
  penaltyPercentage: number;
}): Promise<{ pointsEarned: number; feedback: string }> {
  const { questionText, correctAnswer, studentAnswer, justification, correctionCriteria, maxPoints, penaltyPercentage } = params;

  const prompt = `¬øLa justificaci√≥n del estudiante dice lo mismo que la pauta?

PAUTA: ${correctionCriteria || 'Explicar por qu√© es falso'}
ESTUDIANTE: ${justification || '(vac√≠o)'}

REGLA SIMPLE:
- Si el estudiante dice lo mismo que la pauta (aunque con otras palabras) ‚Üí ${maxPoints} puntos
- Si el estudiante NO dice lo que pide la pauta o est√° vac√≠o ‚Üí ${Math.round(maxPoints * (1 - penaltyPercentage) * 100) / 100} puntos

PROHIBIDO:
- NO agregues requisitos que no est√°n en la pauta
- NO pidas m√°s detalle del que tiene la pauta
- Si la pauta dice "la respuesta es 4" y el estudiante dice "la respuesta es 4", es CORRECTO (${maxPoints} pts)

JSON: { "pointsEarned": <n√∫mero>, "feedback": "<m√°ximo 10 palabras>" }`;

  // DEBUG: Log completo ANTES de llamar a la IA
  console.log('\n========== DEBUG V/F Justification ==========');
  console.log('Modelo:', env.OPENAI_MODEL);
  console.log('Pregunta:', questionText);
  console.log('Respuesta correcta:', correctAnswer);
  console.log('Respuesta estudiante:', studentAnswer);
  console.log('Pauta (correctionCriteria):', correctionCriteria);
  console.log('Justificaci√≥n estudiante:', justification);
  console.log('Puntaje m√°ximo:', maxPoints);
  console.log('Penalizaci√≥n:', penaltyPercentage);
  console.log('--- PROMPT COMPLETO ---');
  console.log(prompt);
  console.log('--- FIN PROMPT ---');

  const completion = await openai.chat.completions.create({
    model: env.OPENAI_MODEL,
    messages: [
      {
        role: 'system',
        content: 'Eres un profesor evaluando respuestas de Verdadero/Falso con justificaci√≥n. Respondes solo en formato JSON v√°lido.',
      },
      {
        role: 'user',
        content: prompt,
      },
    ],
    temperature: 0.3,
    response_format: { type: 'json_object' },
  });

  const responseText = completion.choices[0]?.message.content || '{}';

  // DEBUG: Log de la respuesta de la IA
  console.log('--- RESPUESTA IA ---');
  console.log(responseText);
  console.log('========== FIN DEBUG V/F ==========\n');

  const parsed = JSON.parse(responseText);

  return {
    pointsEarned: typeof parsed.pointsEarned === 'number' ? parsed.pointsEarned : 0,
    feedback: parsed.feedback || 'No se pudo generar feedback.',
  };
}

/**
 * Corregir pregunta de matem√°ticas con evaluaci√≥n de unidades
 * @param params - Par√°metros de correcci√≥n
 * @returns Puntaje y feedback
 */
export async function correctMathWithUnits(params: {
  questionText: string;
  correctionCriteria: string;
  maxPoints: number;
  studentAnswer: string;
  requireUnits: boolean;
  unitPenalty: number;
}): Promise<{ pointsEarned: number; feedback: string }> {
  const { questionText, correctionCriteria, maxPoints, studentAnswer, requireUnits, unitPenalty } = params;

  const unitsInstruction = requireUnits
    ? `
EVALUACI√ìN DE UNIDADES: ACTIVADA
PENALIZACI√ìN SI FALTA O EST√Å INCORRECTA: ${unitPenalty * 100}%

Debes evaluar si la respuesta incluye las unidades correctas.
- Infiere la unidad esperada del contexto de la pregunta y la pauta
- Si las unidades faltan o son incorrectas, aplica la penalizaci√≥n al puntaje
- SIEMPRE menciona en el feedback si las unidades est√°n correctas, faltan, o son incorrectas, y cu√°les deber√≠an ser`
    : '';

  const prompt = `Compara el RESULTADO del estudiante con la RESPUESTA CORRECTA.

RESPUESTA CORRECTA: ${correctionCriteria || 'No especificada'}
RESPUESTA DEL ESTUDIANTE: ${studentAnswer}
${unitsInstruction}

EVALUACI√ìN:
- Si el resultado COINCIDE (mismo valor num√©rico): ${maxPoints} puntos
- Si el resultado NO COINCIDE: 0 puntos

IMPORTANTE - REGLAS ESTRICTAS:
- Solo compara RESULTADOS, NO pidas desarrollo ni procedimiento
- La respuesta puede estar en LaTeX (\\frac{1}{2} = 0.5 = 1/2)
- Formatos equivalentes son correctos (1/2 = 0.5 = 0,5)
- NUNCA menciones "desarrollo", "procedimiento" o "demostraci√≥n" en el feedback
- El feedback solo debe decir si es correcto o incorrecto y mostrar la respuesta esperada

Responde SOLO JSON:
{ "pointsEarned": 0 o ${maxPoints}, "feedback": "Correcto" o "Incorrecto. Respuesta esperada: X" }`;

  // DEBUG: Log completo ANTES de llamar a la IA
  console.log('\n========== DEBUG MATH with Units ==========');
  console.log('Modelo:', env.OPENAI_MODEL);
  console.log('Pregunta:', questionText);
  console.log('Pauta (correctionCriteria):', correctionCriteria);
  console.log('Respuesta estudiante:', studentAnswer);
  console.log('Requiere unidades:', requireUnits);
  console.log('Puntaje m√°ximo:', maxPoints);
  console.log('--- PROMPT COMPLETO ---');
  console.log(prompt);
  console.log('--- FIN PROMPT ---');

  const completion = await openai.chat.completions.create({
    model: env.OPENAI_MODEL,
    messages: [
      {
        role: 'system',
        content: 'Eres un profesor experto en matem√°ticas. Corriges respuestas de manera justa y pedag√≥gica. Respondes solo en formato JSON v√°lido.',
      },
      {
        role: 'user',
        content: prompt,
      },
    ],
    temperature: 0.3,
    response_format: { type: 'json_object' },
  });

  const responseText = completion.choices[0]?.message.content || '{}';

  // DEBUG: Log de la respuesta de la IA
  console.log('--- RESPUESTA IA ---');
  console.log(responseText);
  console.log('========== FIN DEBUG MATH ==========\n');

  const parsed = JSON.parse(responseText);

  return {
    pointsEarned: typeof parsed.pointsEarned === 'number' ? parsed.pointsEarned : 0,
    feedback: parsed.feedback || 'No se pudo generar feedback.',
  };
}

/**
 * Evaluar ortograf√≠a y redacci√≥n de todas las respuestas de desarrollo de un estudiante
 * Se llama UNA vez por estudiante, no por pregunta
 * @param params - Par√°metros de evaluaci√≥n
 * @returns Niveles de ortograf√≠a y redacci√≥n con feedback
 */
export async function evaluateSpellingAndWriting(params: {
  answers: Array<{ questionText: string; answer: string }>;
  evaluateSpelling: boolean;
  evaluateWriting: boolean;
}): Promise<{
  spellingLevel: number | null;
  writingLevel: number | null;
  feedback: string;
}> {
  const { answers, evaluateSpelling, evaluateWriting } = params;

  if (!evaluateSpelling && !evaluateWriting) {
    return { spellingLevel: null, writingLevel: null, feedback: '' };
  }

  const answersText = answers
    .map((a, i) => `---\nPregunta ${i + 1}: ${a.questionText}\nRespuesta: ${a.answer}\n---`)
    .join('\n');

  const prompt = `Eres un evaluador de ortograf√≠a y redacci√≥n. Eval√∫a TODAS las respuestas de desarrollo de este estudiante en conjunto.

RESPUESTAS DEL ESTUDIANTE:
${answersText}

EVALUAR ORTOGRAF√çA: ${evaluateSpelling ? 'S√ç' : 'NO'}
EVALUAR REDACCI√ìN: ${evaluateWriting ? 'S√ç' : 'NO'}

CRITERIOS DE EVALUACI√ìN:
- Excelente (100%): Sin errores o errores m√≠nimos que no afectan la lectura
- Competente (75%): Pocos errores, no afectan comprensi√≥n
- En desarrollo (50%): Varios errores que distraen al lector
- Insuficiente (25%): Errores frecuentes que dificultan la comprensi√≥n
- Muy deficiente (0%): Errores graves que impiden entender el texto

INSTRUCCIONES:
1. Eval√∫a el conjunto de respuestas, no cada una por separado
2. Asigna un nivel (0, 25, 50, 75, o 100)
3. El feedback DEBE ser espec√≠fico:
   - Citar errores exactos encontrados
   - Mostrar la correcci√≥n para cada error
   - Dar ejemplos concretos de c√≥mo mejorar la redacci√≥n
   - Mencionar en qu√© pregunta est√° cada error

EJEMPLO DE FEEDBACK ESPEC√çFICO:
"Errores de ortograf√≠a: ¬´atravez¬ª ‚Üí ¬´a trav√©s¬ª (pregunta 2), ¬´enserio¬ª ‚Üí ¬´en serio¬ª (pregunta 4).
Redacci√≥n: En la pregunta 2, la oraci√≥n ¬´El movimiento que fue causado por la fuerza que se aplic√≥¬ª es redundante; mejor: ¬´El movimiento fue causado por la fuerza aplicada¬ª. Evita oraciones de m√°s de 30 palabras."

IMPORTANTE: No incluyas frases motivacionales gen√©ricas al final del feedback como "¬°Sigue as√≠!", "¬°Buen intento!", "¬°√Ånimo!". Termina el feedback con informaci√≥n √∫til y espec√≠fica.

Responde SOLO con JSON:
{
  "spellingLevel": ${evaluateSpelling ? '<0|25|50|75|100>' : 'null'},
  "writingLevel": ${evaluateWriting ? '<0|25|50|75|100>' : 'null'},
  "feedback": "<texto espec√≠fico con ejemplos>"
}`;

  const completion = await openai.chat.completions.create({
    model: env.OPENAI_MODEL,
    messages: [
      {
        role: 'system',
        content: 'Eres un experto en evaluaci√≥n de ortograf√≠a y redacci√≥n en espa√±ol. Proporcionas feedback espec√≠fico y constructivo. Respondes solo en formato JSON v√°lido.',
      },
      {
        role: 'user',
        content: prompt,
      },
    ],
    temperature: 0.3,
    response_format: { type: 'json_object' },
  });

  const responseText = completion.choices[0]?.message.content || '{}';
  const parsed = JSON.parse(responseText);

  return {
    spellingLevel: typeof parsed.spellingLevel === 'number' ? parsed.spellingLevel : null,
    writingLevel: typeof parsed.writingLevel === 'number' ? parsed.writingLevel : null,
    feedback: parsed.feedback || '',
  };
}

type RubricQuestion = {
  id: string;
  question_number: number;
  question_label: string | null;
  type: string;
  question_text: string;
  points: number;
};

type RubricSuggestion = {
  question_id: string;
  question_number: string;
  correct_answer: string | null;
  correction_criteria: string | null;
  points: number | null;
  options: {
    require_justification: boolean;
    justification_criteria: string | null;
    evaluate_spelling: boolean;
    spelling_points: number;
    evaluate_writing: boolean;
    writing_points: number;
    require_units: boolean;
    unit_penalty: number;
  };
};

const RUBRIC_SYSTEM_PROMPT = `Eres un experto en an√°lisis de pautas de correcci√≥n educativas. Mapeas respuestas correctas y criterios de evaluaci√≥n a preguntas de pruebas. Respondes solo en formato JSON v√°lido.`;

function buildRubricUserPrompt(questionsContext: any[], chunkInfo?: string): string {
  const chunkNote = chunkInfo
    ? `\n\nNOTA: Este es un fragmento de la pauta (${chunkInfo}). Solo extrae las respuestas que encuentres en ESTE fragmento. Si una pregunta no tiene respuesta en este fragmento, NO la incluyas en la respuesta.\n`
    : '';

  return `Extrae las respuestas de esta pauta de correcci√≥n PDF y map√©alas a las preguntas de la prueba.
${chunkNote}
PREGUNTAS DE LA PRUEBA:
${JSON.stringify(questionsContext, null, 2)}

INSTRUCCIONES:
Para cada pregunta, busca en la pauta la respuesta correspondiente usando el n√∫mero de pregunta como referencia.

REGLA FUNDAMENTAL: Tu trabajo es COPIAR/EXTRAER la informaci√≥n de la pauta, NO interpretarla ni reescribirla. La pauta ser√° usada despu√©s por otra IA para corregir respuestas de estudiantes, as√≠ que necesita el contenido textual exacto.

REGLAS POR TIPO DE PREGUNTA:

1. TRUE_FALSE:
   - "correct_answer" = "Verdadero" o "Falso" (SIEMPRE usar estas palabras completas, NUNCA "V" o "F")
   - Si la pauta dice que la afirmaci√≥n es verdadera ‚Üí "Verdadero"
   - Si la pauta dice que es falsa ‚Üí "Falso"
   - Si la pauta indica que el estudiante debe justificar ‚Üí activa "require_justification" y copia la justificaci√≥n de la pauta en "justification_criteria"

2. MULTIPLE_CHOICE:
   - "correct_answer" = la letra correcta ("A", "B", "C", "D")

3. DEVELOPMENT:
   - "correct_answer" = null (no se usa para desarrollo)
   - "correction_criteria" = COPIAR TEXTUALMENTE la respuesta/pauta que da el documento. NO resumir, NO parafrasear, NO escribir criterios de evaluaci√≥n gen√©ricos. Este texto ser√° usado despu√©s por otra IA para corregir.
   - EJEMPLO CORRECTO: Si la pauta dice "Reflexi√≥n de la luz: Es el fen√≥meno en el cual la luz rebota al chocar con una superficie. Ejemplo: Cuando nos vemos en un espejo."
     ‚Üí correct_answer: null, correction_criteria: "Reflexi√≥n de la luz: Es el fen√≥meno en el cual la luz rebota al chocar con una superficie. Ejemplo: Cuando nos vemos en un espejo."
   - EJEMPLO INCORRECTO: correction_criteria: "La respuesta debe incluir la definici√≥n del fen√≥meno y un ejemplo claro." ‚Üê ESTO EST√Å MAL, no inventes criterios gen√©ricos.

4. MATH:
   - "correct_answer" = null (no se usa para matem√°ticas)
   - "correction_criteria" = SOLO el resultado num√©rico o expresi√≥n matem√°tica. NUNCA incluir texto explicativo. Este valor ser√° comparado directamente con la respuesta del estudiante.
   - Si la pauta tiene texto adicional junto al resultado (explicaciones, procedimientos), IGNORAR el texto y extraer SOLO el n√∫mero/expresi√≥n.
   - EJEMPLO: Si la pauta dice "El resultado es 42 cm, ya que se debe sumar las dos longitudes" ‚Üí correct_answer: null, correction_criteria: "42 cm"

OPCIONES AVANZADAS:
- Si la pauta menciona "ortograf√≠a" ‚Üí evaluate_spelling: true, spelling_points: puntaje indicado
- Si la pauta menciona "redacci√≥n" ‚Üí evaluate_writing: true, writing_points: puntaje indicado
- Si la pauta menciona "unidades" (en preguntas MATH) ‚Üí require_units: true, unit_penalty: porcentaje indicado (0.5 = 50%)
- Si NO se menciona, dejar en false/0
- "points" solo se incluye si la pauta especifica un puntaje DIFERENTE al actual; si no, usar null

IMPORTANTE:
- Usa el campo "id" de cada pregunta como "question_id" en la respuesta
- Si no puedes mapear alguna pregunta en este fragmento, simplemente no la incluyas
- El campo "number" corresponde a la nomenclatura visible de la pregunta (puede ser "1", "I.a", "2.b", etc.)

Responde SOLO con JSON v√°lido:
{
  "questions": [
    {
      "question_id": "id-de-la-pregunta",
      "question_number": "1",
      "correct_answer": "valor o null",
      "correction_criteria": "pauta o null",
      "points": null,
      "options": {
        "require_justification": false,
        "justification_criteria": null,
        "evaluate_spelling": false,
        "spelling_points": 0,
        "evaluate_writing": false,
        "writing_points": 0,
        "require_units": false,
        "unit_penalty": 0
      }
    }
  ]
}`;
}

/**
 * Analizar un chunk de pauta de correcci√≥n con IA
 */
async function analyzeRubricChunk(
  chunkBase64: string,
  questionsContext: any[],
  chunkInfo?: string
): Promise<RubricSuggestion[]> {
  const startTime = Date.now();
  const userPrompt = buildRubricUserPrompt(questionsContext, chunkInfo);

  const completion = await openai.chat.completions.create({
    model: env.OPENAI_VISION_MODEL,
    messages: [
      {
        role: 'system',
        content: RUBRIC_SYSTEM_PROMPT,
      },
      {
        role: 'user',
        content: [
          {
            type: 'text',
            text: userPrompt,
          },
          {
            type: 'file',
            file: {
              filename: 'pauta.pdf',
              file_data: `data:application/pdf;base64,${chunkBase64}`,
            },
          },
        ],
      },
    ],
    temperature: 0.0,
    max_tokens: 16000,
    response_format: { type: 'json_object' },
  });

  const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);
  const responseText = completion.choices[0]?.message.content || '{}';
  const parsed = JSON.parse(responseText);
  const suggestions = parsed.questions || [];

  console.log(`  üìù [${elapsed}s] Rubric chunk: ${suggestions.length} mapeos encontrados`);

  return suggestions;
}

// M√°ximo de preguntas por llamada a la API para evitar truncamiento de output
const RUBRIC_QUESTIONS_PER_BATCH = 20;

/**
 * Analizar pauta de correcci√≥n y mapear respuestas a preguntas existentes.
 * Soporta doble batching: PDF chunks √ó question batches.
 * Para 65 preguntas con 1 chunk: ceil(65/20) = 4 llamadas API.
 * @param rubricChunks - Array de chunks del PDF (base64 + metadata)
 * @param questions - Preguntas existentes de la prueba
 * @param onProgress - Optional callback para reportar progreso
 * @returns Sugerencias de respuestas/criterios por pregunta
 */
export async function analyzeRubric(
  rubricChunks: Array<{ base64: string; startPage: number; endPage: number; totalPages: number }>,
  questions: RubricQuestion[],
  onProgress?: ProgressCallback
): Promise<RubricSuggestion[]> {
  const questionsContext = questions.map(q => ({
    id: q.id,
    number: q.question_label || String(q.question_number),
    type: q.type,
    text: q.question_text,
    points: q.points,
  }));

  // Dividir preguntas en batches de RUBRIC_QUESTIONS_PER_BATCH
  const questionBatches: typeof questionsContext[] = [];
  for (let i = 0; i < questionsContext.length; i += RUBRIC_QUESTIONS_PER_BATCH) {
    questionBatches.push(questionsContext.slice(i, i + RUBRIC_QUESTIONS_PER_BATCH));
  }

  const totalApiCalls = rubricChunks.length * questionBatches.length;
  console.log(`üìã Analizando pauta: ${rubricChunks[0].totalPages} p√°ginas, ${questions.length} preguntas ‚Üí ${rubricChunks.length} PDF chunks √ó ${questionBatches.length} question batches = ${totalApiCalls} llamadas API`);

  const allSuggestions: RubricSuggestion[] = [];
  const seenQuestionIds = new Set<string>();
  let currentCall = 0;

  for (let ci = 0; ci < rubricChunks.length; ci++) {
    const chunk = rubricChunks[ci];
    const chunkInfo = rubricChunks.length > 1
      ? `p√°ginas ${chunk.startPage}-${chunk.endPage} de ${chunk.totalPages}`
      : undefined;

    for (let qi = 0; qi < questionBatches.length; qi++) {
      currentCall++;
      const qBatch = questionBatches[qi];
      const qStart = qi * RUBRIC_QUESTIONS_PER_BATCH + 1;
      const qEnd = qStart + qBatch.length - 1;

      const progressMsg = questionBatches.length > 1
        ? `Procesando preguntas ${qStart}-${qEnd} (batch ${currentCall} de ${totalApiCalls})...`
        : `Analizando pauta (${chunk.totalPages} p√°ginas)...`;

      console.log(`  üîÑ [${currentCall}/${totalApiCalls}] Preguntas ${qStart}-${qEnd}${chunkInfo ? `, ${chunkInfo}` : ''}...`);

      onProgress?.({
        type: 'progress',
        batch: currentCall,
        totalBatches: totalApiCalls,
        pages: chunkInfo ? `${chunk.startPage}-${chunk.endPage}` : `1-${chunk.totalPages}`,
        questionsFound: allSuggestions.length,
        message: progressMsg,
      });

      const suggestions = await analyzeRubricChunk(chunk.base64, qBatch, chunkInfo);
      console.log(`  ‚úÖ [${currentCall}/${totalApiCalls}] ${suggestions.length} mapeos encontrados`);

      // Merge: first answer wins (avoid duplicates)
      for (const suggestion of suggestions) {
        if (!seenQuestionIds.has(suggestion.question_id) &&
            (suggestion.correct_answer !== null || suggestion.correction_criteria !== null)) {
          seenQuestionIds.add(suggestion.question_id);
          allSuggestions.push(suggestion);
        }
      }
    }
  }

  console.log(`üìã Total: ${allSuggestions.length}/${questions.length} preguntas mapeadas en ${totalApiCalls} llamadas`);
  return allSuggestions;
}

export default openai;
